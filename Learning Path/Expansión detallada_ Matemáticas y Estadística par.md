# ğŸ§® Fase 2 â€” Fundamentos MatemÃ¡ticos y EstadÃ­sticos para Ciencia de Datos

### ğŸ¯ Objetivo General

Desarrollar un dominio sÃ³lido de las **matemÃ¡ticas esenciales** aplicadas a ciencia de datos: **Ã¡lgebra lineal**, **cÃ¡lculo**, **probabilidad** y **estadÃ­stica**, con orientaciÃ³n prÃ¡ctica en Python. Esta fase habilita la comprensiÃ³n profunda de modelos y algoritmos de machine learning, mÃ¡s allÃ¡ del uso mecÃ¡nico de librerÃ­as.

---

## ğŸ”¸ Nivel 1 â€” Ãlgebra Lineal Computacional

> *â€œNo hay machine learning sin vectores, matrices y transformaciones.â€*

### ğŸ¯ OKR

- Comprender estructuras fundamentales: vectores, matrices y transformaciones lineales.
- Aplicar operaciones matriciales para manipulaciÃ³n de datos y reducciÃ³n de dimensionalidad.
- Implementar conceptos bÃ¡sicos con Python (NumPy).

### ğŸ“š Recursos Clave

- ğŸ“˜ *Essential Math for Data Science* â€“ Oâ€™Reilly.
- ğŸ“˜ *Mathematics for Machine Learning* â€“ Deisenroth et al. (Cap. 1â€“3)
- ğŸ”§ [Curso: Linear Algebra â€“ 3Blue1Brown](https://www.3blue1brown.com/essence-of-linear-algebra)

### ğŸ§± Contenidos

- Espacios vectoriales y Ã¡lgebra de vectores.
- Producto escalar y norma vectorial.
- Producto matricial, identidad, inversa, determinante.
- Sistemas de ecuaciones lineales.
- Eigenvectores y valores propios.
- IntroducciÃ³n a PCA (anÃ¡lisis de componentes principales).
- VisualizaciÃ³n geomÃ©trica con Matplotlib y Python.

### ğŸ›  Mini-proyectos

| Proyecto                                        | Conceptos aplicados        |
| ---------------------------------------------- | -------------------------- |
| ReducciÃ³n de imÃ¡genes en blanco y negro con PCA | Matrices, eigenvectores    |
| Simulador de transformaciones lineales en 2D    | MultiplicaciÃ³n de matrices |

---

## ğŸ”¸ Nivel 2 â€” CÃ¡lculo Aplicado a Machine Learning

> *â€œEl descenso por gradiente se basa en derivadas. El ajuste de modelos, en optimizaciÃ³n.â€*

### ğŸ¯ OKR

- Entender funciones, derivadas e integrales en contexto de optimizaciÃ³n.
- Aplicar el cÃ¡lculo a problemas bÃ¡sicos de minimizaciÃ³n de funciones de pÃ©rdida.
- Programar funciones derivadas y analizar su comportamiento.

### ğŸ“š Recursos Clave

- ğŸ“˜ *Mathematics for Machine Learning* â€“ Cap. 4â€“5.
- ğŸ“˜ *Essential Math for Data Science* â€“ SecciÃ³n de cÃ¡lculo diferencial.
- ğŸ“˜ *Calculus Made Easy* â€“ Thompson.
- ğŸ”§ [Khan Academy: CÃ¡lculo diferencial e integral](https://es.khanacademy.org/math/calculus-1)

### ğŸ§± Contenidos

- Funciones: lineales, polinÃ³micas, exponenciales.
- LÃ­mites, continuidad, derivadas.
- Derivadas parciales y gradientes.
- Reglas de la cadena y optimizaciÃ³n.
- Concepto de integral como Ã¡rea bajo la curva.
- Aplicaciones del gradiente: descenso por gradiente y ajustes.

### ğŸ›  Mini-proyectos

| Proyecto                                                   | Conceptos aplicados   |
| ---------------------------------------------------------- | --------------------- |
| VisualizaciÃ³n del descenso por gradiente en una parÃ¡bola   | Derivadas, gradientes |
| AproximaciÃ³n del Ã¡rea bajo una curva con mÃ©todos numÃ©ricos | Integrales            |

---

## ğŸ”¸ Nivel 3 â€” Fundamentos de Probabilidad y EstadÃ­stica

> *â€œLa estadÃ­stica es el alma de los modelos predictivos.â€*

### ğŸ¯ OKR

- Modelar la incertidumbre con probabilidad.
- Describir datos, distribuciones y estimar parÃ¡metros con estadÃ­stica.
- Aplicar conceptos de inferencia, estimaciÃ³n y pruebas de hipÃ³tesis.

### ğŸ“š Recursos Clave

- ğŸ“˜ *EstadÃ­stica: 50 conceptos fundamentales con Python* â€“ David Spiegelhalter.
- ğŸ“˜ *Essential Math for Data Science* â€“ Secciones 3 y 4.
- ğŸ“˜ *Think Stats* â€“ Allen B. Downey (gratuito en lÃ­nea).
- ğŸ”§ [Curso: Intro to Statistics â€“ Stanford Online](https://online.stanford.edu/courses/sohs-ystatslearning-statistics)

### ğŸ§± Contenidos

#### ğŸ“Œ Probabilidad

- Espacios muestrales y eventos.
- Reglas de la probabilidad (suma, producto, Bayes).
- Variables aleatorias (discretas y continuas).
- Distribuciones (Binomial, Normal, Poisson).

#### ğŸ“Œ EstadÃ­stica Descriptiva

- Media, mediana, moda.
- Varianza, desviaciÃ³n estÃ¡ndar.
- VisualizaciÃ³n de datos: histogramas, boxplots.

#### ğŸ“Œ Inferencia EstadÃ­stica

- EstimaciÃ³n de parÃ¡metros.
- Intervalos de confianza.
- Pruebas de hipÃ³tesis (t, z, chi-cuadrado).
- CorrelaciÃ³n y causalidad.

### ğŸ›  Mini-proyectos

| Proyecto                                   | Conceptos aplicados   |
| ------------------------------------------ | --------------------- |
| SimulaciÃ³n de dados y monedas              | Probabilidad discreta |
| Estudio de salarios en Colombia            | Medidas descriptivas  |
| EvaluaciÃ³n de diferencias entre dos grupos | Prueba t              |

---

## ğŸ”¸ Nivel 4 â€” Modelos EstadÃ­sticos Fundamentales

> *â€œAntes de usar una red neuronal, domina una regresiÃ³n lineal.â€*

### ğŸ¯ OKR

- Entender modelos de regresiÃ³n como herramientas de predicciÃ³n.
- Implementar regresiÃ³n lineal y logÃ­stica en Python (desde cero y con `scikit-learn`).
- Evaluar y validar modelos con mÃ©tricas estadÃ­sticas.

### ğŸ“š Recursos Clave

- ğŸ“˜ *An Introduction to Statistical Learning (ISLR)* â€“ Cap. 3â€“4.
- ğŸ“˜ *Hands-On ML with Scikit-learn* â€“ CapÃ­tulos iniciales.
- ğŸ”§ [Curso: Fundamentos de ML â€“ fast.ai](https://course.fast.ai/)

### ğŸ§± Contenidos

- RegresiÃ³n lineal simple y mÃºltiple.
- Supuestos del modelo lineal.
- RegresiÃ³n logÃ­stica (clasificaciÃ³n binaria).
- Overfitting, regularizaciÃ³n (Ridge, Lasso).
- MÃ©tricas: MAE, MSE, RÂ², precisiÃ³n, recall, F1-score.

### ğŸ›  Mini-proyectos

| Proyecto                                                  | Conceptos aplicados |
| --------------------------------------------------------- | ------------------- |
| PredicciÃ³n del puntaje de matemÃ¡ticas vs horas de estudio | RegresiÃ³n lineal    |
| Clasificador de spam con texto vectorizado                | RegresiÃ³n logÃ­stica |

---

## ğŸ’¡ Recomendaciones para Integrar ProgramaciÃ³n y MatemÃ¡ticas

| Estrategia                                 | Ejemplo                                                                   |
| ------------------------------------------ | ------------------------------------------------------------------------- |
| ğŸ§ª ExperimentaciÃ³n activa                  | Visualizar cÃ³mo cambia la pendiente en una funciÃ³n al ajustar su derivada |
| ğŸ”¢ CÃ³digo como herramienta de comprobaciÃ³n | Calcular media y varianza con NumPy y verificar manualmente               |
| ğŸ“Š VisualizaciÃ³n constante                 | Ver histogramas, dispersiÃ³n, transformaciones vectoriales                 |
| ğŸ” Proyectos de cierre por nivel           | Terminar cada etapa con un anÃ¡lisis o simulaciÃ³n de datos reales          |

---

## ğŸ“˜ EvaluaciÃ³n del Progreso y ConsolidaciÃ³n

### âœ… Checkpoints por nivel

- **Ãlgebra lineal**: Implementar PCA bÃ¡sico.
- **CÃ¡lculo**: Implementar y graficar descenso por gradiente.
- **EstadÃ­stica**: Interpretar distribuciones reales (e.g., salarios, COVID).
- **Modelos**: Predecir outcomes con regresiÃ³n lineal + interpretaciÃ³n.

### ğŸ“ Portafolio inicial

- Notebooks con visualizaciones, simulaciones, modelos.
- Reportes de anÃ¡lisis bÃ¡sico con Markdown.
- Mini-datasets procesados por ti.

---

## ğŸ§­ Referencias

[^1]: [Essential Math for Data Science â€“ Oâ€™Reilly](https://www.oreilly.com/library/view/essential-math-for/9781098115560/)
[^2]: [Mathematics for Machine Learning â€“ Deisenroth et al.](https://mml-book.github.io/)
[^3]: [EstadÃ­stica: 50 conceptos fundamentales con Python â€“ Spiegelhalter](https://www.alianzaeditorial.es/libro/educacion/estadistica-50-conceptos-fundamentales-con-python-david-spiegelhalter-9788411482052/)
[^4]: [Think Stats â€“ Allen B. Downey](https://greenteapress.com/wp/think-stats/)
[^5]: [Khan Academy â€“ CÃ¡lculo y EstadÃ­stica](https://es.khanacademy.org)
[^6]: [3Blue1Brown â€“ Ãlgebra Lineal](https://www.3blue1brown.com/essence-of-linear-algebra)

---

